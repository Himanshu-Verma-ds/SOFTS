{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Guidance for training a model with your own data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3fbf38ad2f4ccaa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import the necessary packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e474201f7f64ab4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from exp.exp_custom import Exp_Custom"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T11:50:10.850064500Z",
     "start_time": "2024-06-13T11:50:10.353719400Z"
    }
   },
   "id": "356a8bc9c1e1349c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Define the hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4b69019515b59d7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(activation='gelu', batch_size=16, checkpoints='./checkpoints/', d_core=64, d_ff=128, d_model=128, data='ETTm1', data_path='ETTm1.csv', dropout=0.0, e_layers=2, features='M', freq='h', gpu='0', learning_rate=0.0003, lradj='cosine', model='SOFTS', num_workers=0, patience=3, pred_len=96, root_path='./dataset/ETT-small/', save_model=True, seq_len=96, train_epochs=50, use_gpu=True, use_norm=True)\n"
     ]
    }
   ],
   "source": [
    "# fix seed for reproducibility\n",
    "fix_seed = 2021\n",
    "random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "np.random.seed(fix_seed)\n",
    "torch.set_num_threads(6)\n",
    "\n",
    "# basic config\n",
    "config = {\n",
    "    # dataset settings\n",
    "    'root_path': './dataset/ETT-small/',\n",
    "    'data_path': 'ETTm1.csv',\n",
    "    'data': 'ETTm1',\n",
    "    'features': 'M',\n",
    "    'freq': 'h',\n",
    "    'seq_len': 96,\n",
    "    'pred_len': 96,\n",
    "    # model settings\n",
    "    'model': 'SOFTS',\n",
    "    'checkpoints': './checkpoints/',\n",
    "    'd_model': 128,\n",
    "    'd_core': 64,\n",
    "    'd_ff': 128,\n",
    "    'e_layers': 2,\n",
    "    'learning_rate': 0.0003,\n",
    "    'lradj': 'cosine',\n",
    "    'train_epochs': 50,\n",
    "    'patience': 3,\n",
    "    'batch_size': 16,\n",
    "    'dropout': 0.0,\n",
    "    'activation': 'gelu',\n",
    "    'use_norm': True,\n",
    "    # system settings\n",
    "    'num_workers': 0,\n",
    "    'use_gpu': True,\n",
    "    'gpu': '0',\n",
    "    'save_model': True,\n",
    "}\n",
    "\n",
    "parser = argparse.ArgumentParser(description='SOFTS')\n",
    "args = parser.parse_args([])\n",
    "args.__dict__.update(config)\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "print('Args in experiment:')\n",
    "print(args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T11:50:10.910504100Z",
     "start_time": "2024-06-13T11:50:10.854055Z"
    }
   },
   "id": "e886ee3de8bbb1e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Prepare the dataset\n",
    "Organize your data in the following format:\n",
    "- The dataset should be a csv file.\n",
    "- If there is a time feature, the first column contains timestamps in the format 'YYYY-MM-DD HH:MM'. If there's no time feature, the dataset starts directly with the features.\n",
    "- If the parameter `features` is 'M', the following columns are both the features and the targets. If `features` is 'MS', the following columns are the features, and the last column is the target."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171fc13ff2726f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date   HUFL   HULL   MUFL   MULL   LUFL   LULL         OT\n",
      "0  2016-07-01 00:00:00  5.827  2.009  1.599  0.462  4.203  1.340  30.531000\n",
      "1  2016-07-01 00:15:00  5.760  2.076  1.492  0.426  4.264  1.401  30.459999\n",
      "2  2016-07-01 00:30:00  5.760  1.942  1.492  0.391  4.234  1.310  30.038000\n",
      "3  2016-07-01 00:45:00  5.760  1.942  1.492  0.426  4.234  1.310  27.013000\n",
      "4  2016-07-01 01:00:00  5.693  2.076  1.492  0.426  4.142  1.371  27.787001\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
    "print(data.head())\n",
    "\n",
    "# split data\n",
    "train_data = data.iloc[: 12 * 30 * 24 * 4]\n",
    "vali_data = data.iloc[12 * 30 * 24 * 4 - args.seq_len: 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4]\n",
    "test_data = data.iloc[12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - args.seq_len: 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4]\n",
    "\n",
    "# optional: scale data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if 'date' in train_data.columns:\n",
    "    scaler.fit(train_data.iloc[:, 1:])\n",
    "    train_data.iloc[:, 1:] = scaler.transform(train_data.iloc[:, 1:])\n",
    "    vali_data.iloc[:, 1:] = scaler.transform(vali_data.iloc[:, 1:])\n",
    "    test_data.iloc[:, 1:] = scaler.transform(test_data.iloc[:, 1:])\n",
    "else:\n",
    "    scaler.fit(train_data.iloc[:, :])\n",
    "    train_data.iloc[:, :] = scaler.transform(train_data.iloc[:, :])\n",
    "    vali_data.iloc[:, :] = scaler.transform(vali_data.iloc[:, :])\n",
    "    test_data.iloc[:, :] = scaler.transform(test_data.iloc[:, :])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T11:50:11.224836300Z",
     "start_time": "2024-06-13T11:50:10.915488600Z"
    }
   },
   "id": "8bc7a801398c68de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Train and Evaluate the model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c04cef58eb7d57d6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTm1_SOFTS_96_96>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\titers: 100, epoch: 1 | loss: 0.4506244\n",
      "\tspeed: 0.0286s/iter; left time: 3072.1327s\n",
      "\titers: 200, epoch: 1 | loss: 0.2323690\n",
      "\tspeed: 0.0056s/iter; left time: 595.4584s\n",
      "\titers: 300, epoch: 1 | loss: 0.4256146\n",
      "\tspeed: 0.0058s/iter; left time: 624.7960s\n",
      "\titers: 400, epoch: 1 | loss: 0.2308036\n",
      "\tspeed: 0.0061s/iter; left time: 655.3752s\n",
      "\titers: 500, epoch: 1 | loss: 0.2784870\n",
      "\tspeed: 0.0057s/iter; left time: 609.0591s\n",
      "\titers: 600, epoch: 1 | loss: 0.3876713\n",
      "\tspeed: 0.0053s/iter; left time: 561.7736s\n",
      "\titers: 700, epoch: 1 | loss: 0.2946256\n",
      "\tspeed: 0.0052s/iter; left time: 553.6901s\n",
      "\titers: 800, epoch: 1 | loss: 0.2888232\n",
      "\tspeed: 0.0053s/iter; left time: 568.7204s\n",
      "\titers: 900, epoch: 1 | loss: 0.2390691\n",
      "\tspeed: 0.0054s/iter; left time: 578.2185s\n",
      "\titers: 1000, epoch: 1 | loss: 0.2671814\n",
      "\tspeed: 0.0086s/iter; left time: 911.7243s\n",
      "\titers: 1100, epoch: 1 | loss: 0.2918743\n",
      "\tspeed: 0.0060s/iter; left time: 635.4339s\n",
      "\titers: 1200, epoch: 1 | loss: 0.1836184\n",
      "\tspeed: 0.0054s/iter; left time: 577.9823s\n",
      "\titers: 1300, epoch: 1 | loss: 0.2745768\n",
      "\tspeed: 0.0050s/iter; left time: 527.3404s\n",
      "\titers: 1400, epoch: 1 | loss: 0.2791349\n",
      "\tspeed: 0.0057s/iter; left time: 607.2469s\n",
      "\titers: 1500, epoch: 1 | loss: 0.2686602\n",
      "\tspeed: 0.0050s/iter; left time: 528.4723s\n",
      "\titers: 1600, epoch: 1 | loss: 0.4751884\n",
      "\tspeed: 0.0065s/iter; left time: 689.5897s\n",
      "\titers: 1700, epoch: 1 | loss: 0.2222381\n",
      "\tspeed: 0.0050s/iter; left time: 528.4479s\n",
      "\titers: 1800, epoch: 1 | loss: 0.2600937\n",
      "\tspeed: 0.0050s/iter; left time: 524.7021s\n",
      "\titers: 1900, epoch: 1 | loss: 0.3446293\n",
      "\tspeed: 0.0053s/iter; left time: 556.7784s\n",
      "\titers: 2000, epoch: 1 | loss: 0.2382944\n",
      "\tspeed: 0.0050s/iter; left time: 523.7898s\n",
      "\titers: 2100, epoch: 1 | loss: 0.2264607\n",
      "\tspeed: 0.0051s/iter; left time: 532.6318s\n",
      "Epoch: 1 cost time: 14.31116008758545\n",
      "Validation loss decreased (inf --> 0.420679).  Saving model ...\n",
      "Epoch: 1, Steps: 2149 | Train Loss: 0.2933352 Vali Loss: 0.4206790 Test Loss: 0.3356791\n",
      "Updating learning rate to 0.0002997040092642407\n",
      "\titers: 100, epoch: 2 | loss: 0.2879750\n",
      "\tspeed: 0.0249s/iter; left time: 2615.6993s\n",
      "\titers: 200, epoch: 2 | loss: 0.2676999\n",
      "\tspeed: 0.0063s/iter; left time: 661.2830s\n",
      "\titers: 300, epoch: 2 | loss: 0.3097526\n",
      "\tspeed: 0.0058s/iter; left time: 604.5086s\n",
      "\titers: 400, epoch: 2 | loss: 0.2897035\n",
      "\tspeed: 0.0052s/iter; left time: 549.3813s\n",
      "\titers: 500, epoch: 2 | loss: 0.2596558\n",
      "\tspeed: 0.0050s/iter; left time: 526.0782s\n",
      "\titers: 600, epoch: 2 | loss: 0.3919277\n",
      "\tspeed: 0.0054s/iter; left time: 569.2378s\n",
      "\titers: 700, epoch: 2 | loss: 0.2498662\n",
      "\tspeed: 0.0053s/iter; left time: 549.8888s\n",
      "\titers: 800, epoch: 2 | loss: 0.3093124\n",
      "\tspeed: 0.0053s/iter; left time: 549.6058s\n",
      "\titers: 900, epoch: 2 | loss: 0.2771933\n",
      "\tspeed: 0.0076s/iter; left time: 796.2510s\n",
      "\titers: 1000, epoch: 2 | loss: 0.4784857\n",
      "\tspeed: 0.0066s/iter; left time: 686.6635s\n",
      "\titers: 1100, epoch: 2 | loss: 0.4175684\n",
      "\tspeed: 0.0054s/iter; left time: 566.4732s\n",
      "\titers: 1200, epoch: 2 | loss: 0.3272308\n",
      "\tspeed: 0.0050s/iter; left time: 525.7140s\n",
      "\titers: 1300, epoch: 2 | loss: 0.2790713\n",
      "\tspeed: 0.0051s/iter; left time: 530.4913s\n",
      "\titers: 1400, epoch: 2 | loss: 0.2294715\n",
      "\tspeed: 0.0050s/iter; left time: 518.2595s\n",
      "\titers: 1500, epoch: 2 | loss: 0.2734144\n",
      "\tspeed: 0.0051s/iter; left time: 528.5109s\n",
      "\titers: 1600, epoch: 2 | loss: 0.2556303\n",
      "\tspeed: 0.0049s/iter; left time: 512.1887s\n",
      "\titers: 1700, epoch: 2 | loss: 0.2353841\n",
      "\tspeed: 0.0053s/iter; left time: 552.7154s\n",
      "\titers: 1800, epoch: 2 | loss: 0.2425886\n",
      "\tspeed: 0.0053s/iter; left time: 546.5299s\n",
      "\titers: 1900, epoch: 2 | loss: 0.2627399\n",
      "\tspeed: 0.0052s/iter; left time: 540.2523s\n",
      "\titers: 2000, epoch: 2 | loss: 0.2080787\n",
      "\tspeed: 0.0064s/iter; left time: 664.2497s\n",
      "\titers: 2100, epoch: 2 | loss: 0.2418713\n",
      "\tspeed: 0.0055s/iter; left time: 569.7607s\n",
      "Epoch: 2 cost time: 11.831402063369751\n",
      "Validation loss decreased (0.420679 --> 0.420087).  Saving model ...\n",
      "Epoch: 2, Steps: 2149 | Train Loss: 0.2902201 Vali Loss: 0.4200871 Test Loss: 0.3283640\n",
      "Updating learning rate to 0.0002988172051971717\n",
      "\titers: 100, epoch: 3 | loss: 0.2880904\n",
      "\tspeed: 0.0247s/iter; left time: 2546.2573s\n",
      "\titers: 200, epoch: 3 | loss: 0.2849099\n",
      "\tspeed: 0.0052s/iter; left time: 540.4233s\n",
      "\titers: 300, epoch: 3 | loss: 0.3172294\n",
      "\tspeed: 0.0054s/iter; left time: 552.0373s\n",
      "\titers: 400, epoch: 3 | loss: 0.3554396\n",
      "\tspeed: 0.0051s/iter; left time: 521.0407s\n",
      "\titers: 500, epoch: 3 | loss: 0.3525619\n",
      "\tspeed: 0.0061s/iter; left time: 626.5239s\n",
      "\titers: 600, epoch: 3 | loss: 0.2695810\n",
      "\tspeed: 0.0053s/iter; left time: 542.3616s\n",
      "\titers: 700, epoch: 3 | loss: 0.2115875\n",
      "\tspeed: 0.0050s/iter; left time: 509.2327s\n",
      "\titers: 800, epoch: 3 | loss: 0.3150197\n",
      "\tspeed: 0.0051s/iter; left time: 525.0460s\n",
      "\titers: 900, epoch: 3 | loss: 0.1955295\n",
      "\tspeed: 0.0050s/iter; left time: 509.1019s\n",
      "\titers: 1000, epoch: 3 | loss: 0.3043511\n",
      "\tspeed: 0.0050s/iter; left time: 510.8627s\n",
      "\titers: 1100, epoch: 3 | loss: 0.2362251\n",
      "\tspeed: 0.0049s/iter; left time: 503.3345s\n",
      "\titers: 1200, epoch: 3 | loss: 0.2748100\n",
      "\tspeed: 0.0050s/iter; left time: 504.6850s\n",
      "\titers: 1300, epoch: 3 | loss: 0.2932656\n",
      "\tspeed: 0.0049s/iter; left time: 499.5838s\n",
      "\titers: 1400, epoch: 3 | loss: 0.2300588\n",
      "\tspeed: 0.0061s/iter; left time: 618.7029s\n",
      "\titers: 1500, epoch: 3 | loss: 0.3324521\n",
      "\tspeed: 0.0058s/iter; left time: 587.8847s\n",
      "\titers: 1600, epoch: 3 | loss: 0.2761744\n",
      "\tspeed: 0.0053s/iter; left time: 537.9398s\n",
      "\titers: 1700, epoch: 3 | loss: 0.1916248\n",
      "\tspeed: 0.0054s/iter; left time: 549.2406s\n",
      "\titers: 1800, epoch: 3 | loss: 0.2483542\n",
      "\tspeed: 0.0057s/iter; left time: 581.3200s\n",
      "\titers: 1900, epoch: 3 | loss: 0.2659746\n",
      "\tspeed: 0.0052s/iter; left time: 524.0429s\n",
      "\titers: 2000, epoch: 3 | loss: 0.1941691\n",
      "\tspeed: 0.0052s/iter; left time: 530.1639s\n",
      "\titers: 2100, epoch: 3 | loss: 0.3112955\n",
      "\tspeed: 0.0055s/iter; left time: 559.8648s\n",
      "Epoch: 3 cost time: 11.424428701400757\n",
      "Validation loss decreased (0.420087 --> 0.416802).  Saving model ...\n",
      "Epoch: 3, Steps: 2149 | Train Loss: 0.2737478 Vali Loss: 0.4168020 Test Loss: 0.3290583\n",
      "Updating learning rate to 0.0002973430876093033\n",
      "\titers: 100, epoch: 4 | loss: 0.2467478\n",
      "\tspeed: 0.0283s/iter; left time: 2857.4019s\n",
      "\titers: 200, epoch: 4 | loss: 0.2907024\n",
      "\tspeed: 0.0054s/iter; left time: 544.5540s\n",
      "\titers: 300, epoch: 4 | loss: 0.1952767\n",
      "\tspeed: 0.0048s/iter; left time: 479.5511s\n",
      "\titers: 400, epoch: 4 | loss: 0.2482563\n",
      "\tspeed: 0.0050s/iter; left time: 502.6619s\n",
      "\titers: 500, epoch: 4 | loss: 0.2869221\n",
      "\tspeed: 0.0054s/iter; left time: 547.1996s\n",
      "\titers: 600, epoch: 4 | loss: 0.2432848\n",
      "\tspeed: 0.0058s/iter; left time: 582.6538s\n",
      "\titers: 700, epoch: 4 | loss: 0.2615869\n",
      "\tspeed: 0.0054s/iter; left time: 539.0029s\n",
      "\titers: 800, epoch: 4 | loss: 0.3093148\n",
      "\tspeed: 0.0049s/iter; left time: 495.9435s\n",
      "\titers: 900, epoch: 4 | loss: 0.1970979\n",
      "\tspeed: 0.0072s/iter; left time: 722.4214s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2343193\n",
      "\tspeed: 0.0054s/iter; left time: 535.8968s\n",
      "\titers: 1100, epoch: 4 | loss: 0.2562083\n",
      "\tspeed: 0.0050s/iter; left time: 501.7425s\n",
      "\titers: 1200, epoch: 4 | loss: 0.2822427\n",
      "\tspeed: 0.0052s/iter; left time: 521.2299s\n",
      "\titers: 1300, epoch: 4 | loss: 0.2862186\n",
      "\tspeed: 0.0052s/iter; left time: 514.1047s\n",
      "\titers: 1400, epoch: 4 | loss: 0.2125736\n",
      "\tspeed: 0.0051s/iter; left time: 508.1205s\n",
      "\titers: 1500, epoch: 4 | loss: 0.2899629\n",
      "\tspeed: 0.0054s/iter; left time: 537.3311s\n",
      "\titers: 1600, epoch: 4 | loss: 0.2879072\n",
      "\tspeed: 0.0065s/iter; left time: 641.9694s\n",
      "\titers: 1700, epoch: 4 | loss: 0.2534532\n",
      "\tspeed: 0.0055s/iter; left time: 548.7183s\n",
      "\titers: 1800, epoch: 4 | loss: 0.2427848\n",
      "\tspeed: 0.0052s/iter; left time: 511.6661s\n",
      "\titers: 1900, epoch: 4 | loss: 0.1937304\n",
      "\tspeed: 0.0051s/iter; left time: 505.1360s\n",
      "\titers: 2000, epoch: 4 | loss: 0.2955550\n",
      "\tspeed: 0.0052s/iter; left time: 511.4867s\n",
      "\titers: 2100, epoch: 4 | loss: 0.2177162\n",
      "\tspeed: 0.0054s/iter; left time: 529.4308s\n",
      "Epoch: 4 cost time: 11.574326038360596\n",
      "Validation loss decreased (0.416802 --> 0.407331).  Saving model ...\n",
      "Epoch: 4, Steps: 2149 | Train Loss: 0.2538982 Vali Loss: 0.4073312 Test Loss: 0.3260311\n",
      "Updating learning rate to 0.00029528747416929463\n",
      "\titers: 100, epoch: 5 | loss: 0.2358541\n",
      "\tspeed: 0.0268s/iter; left time: 2649.2127s\n",
      "\titers: 200, epoch: 5 | loss: 0.2369819\n",
      "\tspeed: 0.0052s/iter; left time: 510.8103s\n",
      "\titers: 300, epoch: 5 | loss: 0.2098743\n",
      "\tspeed: 0.0052s/iter; left time: 511.4267s\n",
      "\titers: 400, epoch: 5 | loss: 0.3288191\n",
      "\tspeed: 0.0051s/iter; left time: 500.9663s\n",
      "\titers: 500, epoch: 5 | loss: 0.4056228\n",
      "\tspeed: 0.0051s/iter; left time: 505.6044s\n",
      "\titers: 600, epoch: 5 | loss: 0.2010879\n",
      "\tspeed: 0.0054s/iter; left time: 532.3690s\n",
      "\titers: 700, epoch: 5 | loss: 0.2744911\n",
      "\tspeed: 0.0059s/iter; left time: 577.2352s\n",
      "\titers: 800, epoch: 5 | loss: 0.1945106\n",
      "\tspeed: 0.0050s/iter; left time: 490.6787s\n",
      "\titers: 900, epoch: 5 | loss: 0.1812340\n",
      "\tspeed: 0.0058s/iter; left time: 567.8066s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2142507\n",
      "\tspeed: 0.0057s/iter; left time: 555.0076s\n",
      "\titers: 1100, epoch: 5 | loss: 0.1818398\n",
      "\tspeed: 0.0054s/iter; left time: 528.5512s\n",
      "\titers: 1200, epoch: 5 | loss: 0.2048016\n",
      "\tspeed: 0.0052s/iter; left time: 503.2530s\n",
      "\titers: 1300, epoch: 5 | loss: 0.3843733\n",
      "\tspeed: 0.0051s/iter; left time: 499.5456s\n",
      "\titers: 1400, epoch: 5 | loss: 0.2146500\n",
      "\tspeed: 0.0052s/iter; left time: 509.1153s\n",
      "\titers: 1500, epoch: 5 | loss: 0.1706911\n",
      "\tspeed: 0.0050s/iter; left time: 490.2690s\n",
      "\titers: 1600, epoch: 5 | loss: 0.2873355\n",
      "\tspeed: 0.0061s/iter; left time: 594.1235s\n",
      "\titers: 1700, epoch: 5 | loss: 0.2240126\n",
      "\tspeed: 0.0056s/iter; left time: 542.0504s\n",
      "\titers: 1800, epoch: 5 | loss: 0.2380046\n",
      "\tspeed: 0.0050s/iter; left time: 488.3644s\n",
      "\titers: 1900, epoch: 5 | loss: 0.3126761\n",
      "\tspeed: 0.0049s/iter; left time: 470.9471s\n",
      "\titers: 2000, epoch: 5 | loss: 0.4203324\n",
      "\tspeed: 0.0054s/iter; left time: 524.6503s\n",
      "\titers: 2100, epoch: 5 | loss: 0.2064221\n",
      "\tspeed: 0.0049s/iter; left time: 473.9671s\n",
      "Epoch: 5 cost time: 11.466880559921265\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Epoch: 5, Steps: 2149 | Train Loss: 0.2537079 Vali Loss: 0.4139205 Test Loss: 0.3301461\n",
      "Updating learning rate to 0.00029265847744427303\n",
      "\titers: 100, epoch: 6 | loss: 0.2605379\n",
      "\tspeed: 0.0261s/iter; left time: 2522.0543s\n",
      "\titers: 200, epoch: 6 | loss: 0.1683897\n",
      "\tspeed: 0.0052s/iter; left time: 504.4910s\n",
      "\titers: 300, epoch: 6 | loss: 0.2659087\n",
      "\tspeed: 0.0055s/iter; left time: 532.4515s\n",
      "\titers: 400, epoch: 6 | loss: 0.1988440\n",
      "\tspeed: 0.0057s/iter; left time: 546.4251s\n",
      "\titers: 500, epoch: 6 | loss: 0.2109133\n",
      "\tspeed: 0.0053s/iter; left time: 510.4712s\n",
      "\titers: 600, epoch: 6 | loss: 0.3424521\n",
      "\tspeed: 0.0054s/iter; left time: 519.9677s\n",
      "\titers: 700, epoch: 6 | loss: 0.2633236\n",
      "\tspeed: 0.0052s/iter; left time: 501.2636s\n",
      "\titers: 800, epoch: 6 | loss: 0.3996557\n",
      "\tspeed: 0.0060s/iter; left time: 580.1090s\n",
      "\titers: 900, epoch: 6 | loss: 0.1971629\n",
      "\tspeed: 0.0058s/iter; left time: 555.2156s\n",
      "\titers: 1000, epoch: 6 | loss: 0.1828001\n",
      "\tspeed: 0.0057s/iter; left time: 549.9406s\n",
      "\titers: 1100, epoch: 6 | loss: 0.2320836\n",
      "\tspeed: 0.0053s/iter; left time: 506.8321s\n",
      "\titers: 1200, epoch: 6 | loss: 0.2422465\n",
      "\tspeed: 0.0055s/iter; left time: 520.6312s\n",
      "\titers: 1300, epoch: 6 | loss: 0.2101018\n",
      "\tspeed: 0.0050s/iter; left time: 475.3672s\n",
      "\titers: 1400, epoch: 6 | loss: 0.1730599\n",
      "\tspeed: 0.0051s/iter; left time: 486.1154s\n",
      "\titers: 1500, epoch: 6 | loss: 0.3015074\n",
      "\tspeed: 0.0049s/iter; left time: 463.0769s\n",
      "\titers: 1600, epoch: 6 | loss: 0.2248778\n",
      "\tspeed: 0.0049s/iter; left time: 466.5387s\n",
      "\titers: 1700, epoch: 6 | loss: 0.2006399\n",
      "\tspeed: 0.0062s/iter; left time: 585.3060s\n",
      "\titers: 1800, epoch: 6 | loss: 0.3145465\n",
      "\tspeed: 0.0050s/iter; left time: 479.0030s\n",
      "\titers: 1900, epoch: 6 | loss: 0.2077492\n",
      "\tspeed: 0.0054s/iter; left time: 512.1504s\n",
      "\titers: 2000, epoch: 6 | loss: 0.1928022\n",
      "\tspeed: 0.0049s/iter; left time: 459.9165s\n",
      "\titers: 2100, epoch: 6 | loss: 0.2118652\n",
      "\tspeed: 0.0050s/iter; left time: 472.3371s\n",
      "Epoch: 6 cost time: 11.467068195343018\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Epoch: 6, Steps: 2149 | Train Loss: 0.2381651 Vali Loss: 0.4127691 Test Loss: 0.3371246\n",
      "Updating learning rate to 0.00028946647288323766\n",
      "\titers: 100, epoch: 7 | loss: 0.2260187\n",
      "\tspeed: 0.0253s/iter; left time: 2387.0488s\n",
      "\titers: 200, epoch: 7 | loss: 0.1839273\n",
      "\tspeed: 0.0064s/iter; left time: 600.3201s\n",
      "\titers: 300, epoch: 7 | loss: 0.1823730\n",
      "\tspeed: 0.0053s/iter; left time: 503.6400s\n",
      "\titers: 400, epoch: 7 | loss: 0.1914832\n",
      "\tspeed: 0.0054s/iter; left time: 503.9526s\n",
      "\titers: 500, epoch: 7 | loss: 0.2169700\n",
      "\tspeed: 0.0053s/iter; left time: 500.1685s\n",
      "\titers: 600, epoch: 7 | loss: 0.2720859\n",
      "\tspeed: 0.0056s/iter; left time: 524.8973s\n",
      "\titers: 700, epoch: 7 | loss: 0.1779072\n",
      "\tspeed: 0.0053s/iter; left time: 498.1082s\n",
      "\titers: 800, epoch: 7 | loss: 0.1913169\n",
      "\tspeed: 0.0053s/iter; left time: 499.0439s\n",
      "\titers: 900, epoch: 7 | loss: 0.2312929\n",
      "\tspeed: 0.0058s/iter; left time: 547.0881s\n",
      "\titers: 1000, epoch: 7 | loss: 0.1830410\n",
      "\tspeed: 0.0058s/iter; left time: 541.5587s\n",
      "\titers: 1100, epoch: 7 | loss: 0.3189675\n",
      "\tspeed: 0.0053s/iter; left time: 495.9161s\n",
      "\titers: 1200, epoch: 7 | loss: 0.2285484\n",
      "\tspeed: 0.0051s/iter; left time: 478.6806s\n",
      "\titers: 1300, epoch: 7 | loss: 0.2870460\n",
      "\tspeed: 0.0052s/iter; left time: 482.6558s\n",
      "\titers: 1400, epoch: 7 | loss: 0.1935607\n",
      "\tspeed: 0.0051s/iter; left time: 472.7901s\n",
      "\titers: 1500, epoch: 7 | loss: 0.1845900\n",
      "\tspeed: 0.0053s/iter; left time: 495.0544s\n",
      "\titers: 1600, epoch: 7 | loss: 0.2080109\n",
      "\tspeed: 0.0050s/iter; left time: 463.1501s\n",
      "\titers: 1700, epoch: 7 | loss: 0.1943443\n",
      "\tspeed: 0.0060s/iter; left time: 552.9079s\n",
      "\titers: 1800, epoch: 7 | loss: 0.1713217\n",
      "\tspeed: 0.0057s/iter; left time: 532.9240s\n",
      "\titers: 1900, epoch: 7 | loss: 0.2140364\n",
      "\tspeed: 0.0051s/iter; left time: 474.7116s\n",
      "\titers: 2000, epoch: 7 | loss: 0.3250565\n",
      "\tspeed: 0.0053s/iter; left time: 490.2957s\n",
      "\titers: 2100, epoch: 7 | loss: 0.1656498\n",
      "\tspeed: 0.0055s/iter; left time: 506.6686s\n",
      "Epoch: 7 cost time: 11.671854019165039\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm1_SOFTS_96_96<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "loading model from ./checkpoints/ETTm1_SOFTS_96_96\\checkpoint.pth\n",
      "mse:0.32603105534740295, mae:0.361756386726899\n"
     ]
    }
   ],
   "source": [
    "Exp = Exp_Custom(args)\n",
    "setting = f'{args.data}_{args.model}_{args.seq_len}_{args.pred_len}'\n",
    "print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
    "Exp.train(setting=setting, train_data=train_data, vali_data=vali_data, test_data=test_data)\n",
    "print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
    "Exp.test(setting=setting, test_data=test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T11:51:47.806634400Z",
     "start_time": "2024-06-13T11:50:11.226829400Z"
    }
   },
   "id": "77857ed9da69bd61"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Get predictions by the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c25a79ea1985454"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ./checkpoints/ETTm1_SOFTS_96_96\\checkpoint.pth\n",
      "(11521, 96, 7)\n"
     ]
    }
   ],
   "source": [
    "# get predictions\n",
    "predictions = Exp.predict(setting=setting, pred_data=test_data)\n",
    "print(predictions.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T11:51:48.723496700Z",
     "start_time": "2024-06-13T11:51:47.805638Z"
    }
   },
   "id": "9f0926408d8d19bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
